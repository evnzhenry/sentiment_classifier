{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff173a2e",
   "metadata": {},
   "source": [
    "# AfriSenti Multilingual Sentiment Analysis\n",
    "\n",
    "This notebook guides a reproducible workflow for sentiment analysis on the AfriSenti Twitter dataset (Swahili, Amharic, English).\n",
    "\n",
    "Sections:\n",
    "- Environment & imports\n",
    "- Load dataset & splits\n",
    "- Initial EDA\n",
    "- Preprocessing and tokenization\n",
    "- Model training (Transformer & BiLSTM baseline)\n",
    "- Evaluation, attention visualization, ablations, and cross-lingual tests\n",
    "\n",
    "Note: place AfriSenti CSV files in `./data/` (columns: at least `text`, `label`, `language`) or edit the loader to point to a Hugging Face dataset id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c914c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: install (optional) and imports\n",
    "\n",
    "# If you run in a fresh Colab/Jupyter environment, you can uncomment the install block.\n",
    "# !pip install -r ../requirements.txt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# add project root so `src` can be imported\n",
    "ROOT = Path('c:/Users/BMC/Desktop/NLP').resolve()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# project modules\n",
    "from src.data_exploration import load_afrisenti, simple_eda\n",
    "from src.preprocess import simple_clean\n",
    "from src.tokenize_utils import get_tokenizer, batch_tokenize\n",
    "from src.dataset import SentimentDataset, collate_fn\n",
    "from src.models import TransformerClassifier, BiLSTMClassifier\n",
    "from src.train import Trainer\n",
    "from src.eval_utils import compute_metrics, plot_confusion, compute_roc_auc\n",
    "\n",
    "# set device\n",
    "import torch\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', DEVICE)\n",
    "\n",
    "# reproducibility\n",
    "SEED = 42\n",
    "import random\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AfriSenti dataset\n",
    "\n",
    "DATA_DIR = str(ROOT / 'data')\n",
    "print('Looking for data in', DATA_DIR)\n",
    "\n",
    "# If you have a Hugging Face dataset id, set HF_DATASET_ID = '...' and pass to load_afrisenti\n",
    "HF_DATASET_ID = None\n",
    "\n",
    "try:\n",
    "    df = load_afrisenti(data_dir=DATA_DIR, hf_id=HF_DATASET_ID)\n",
    "    print('Loaded dataframe with', len(df), 'rows')\n",
    "    display(df.head())\n",
    "except Exception as e:\n",
    "    print('Failed to load local dataset:', e)\n",
    "    print('Please place AfriSenti CSV(s) in', DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bcc40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Data Exploration\n",
    "\n",
    "# Run simple EDA (language distribution, label balance, text length)\n",
    "if 'df' in globals():\n",
    "    eda_stats = simple_eda(df, text_col='text', lang_col='language' if 'language' in df.columns else 'lang', label_col='label' if 'label' in df.columns else 'sentiment', show_plots=True, save_prefix=str(ROOT / 'eda'))\n",
    "    print('EDA summary:', eda_stats)\n",
    "else:\n",
    "    print('Dataframe `df` not loaded. Run the data-loading cell.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ecb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing examples\n",
    "\n",
    "from src.preprocess import simple_clean\n",
    "\n",
    "if 'df' in globals():\n",
    "    df['clean_text'] = df['text'].astype(str).apply(simple_clean)\n",
    "    display(df[['text','clean_text']].head(8))\n",
    "else:\n",
    "    print('Dataframe `df` not loaded; run the load cell to continue.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffe081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization comparisons: mBERT, XLM-R, AfriBERTa\n",
    "\n",
    "models = ['mbert', 'xlm-roberta', 'afriberta']\n",
    "samples = []\n",
    "if 'df' in globals():\n",
    "    samples = df['clean_text'].astype(str).dropna().unique()[:6].tolist()\n",
    "else:\n",
    "    samples = [\n",
    "        'I love this! ❤️',\n",
    "        'Hii ni habari nzuri',\n",
    "        'እውነት ነው ይህ',\n",
    "        'This is terrible... so bad',\n",
    "    ]\n",
    "\n",
    "for m in models:\n",
    "    tok = get_tokenizer(m)\n",
    "    enc = tok(samples, truncation=True)\n",
    "    lens = [len(t) for t in enc['input_ids']]\n",
    "    print(f\"\\nModel: {m} (id={tok.name_or_path}) - token lengths: {lens}\")\n",
    "    for s, ids in zip(samples, enc['input_ids']):\n",
    "        print('  text:', s)\n",
    "        print('  tokens:', tok.convert_ids_to_tokens(ids[:30]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch Dataset and DataLoaders\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if 'df' in globals():\n",
    "    # map labels to integers\n",
    "    labels_unique = sorted(df['label'].unique())\n",
    "    label_map = {v:i for i,v in enumerate(labels_unique)}\n",
    "    df['label_id'] = df['label'].map(label_map)\n",
    "\n",
    "    # small stratified split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['label_id'], random_state=SEED)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label_id'], random_state=SEED)\n",
    "\n",
    "    tokenizer = get_tokenizer('xlm-roberta')\n",
    "    train_ds = SentimentDataset(train_df['clean_text'].tolist(), train_df['label_id'].tolist(), tokenizer=tokenizer, max_length=128)\n",
    "    val_ds = SentimentDataset(val_df['clean_text'].tolist(), val_df['label_id'].tolist(), tokenizer=tokenizer, max_length=128)\n",
    "    test_ds = SentimentDataset(test_df['clean_text'].tolist(), test_df['label_id'].tolist(), tokenizer=tokenizer, max_length=128)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    print('Train/val/test sizes:', len(train_ds), len(val_ds), len(test_ds))\n",
    "else:\n",
    "    print('Dataframe `df` not loaded; run the data-loading cell first.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling: Transformer fine-tuning and BiLSTM baseline\n",
    "\n",
    "# Transformer fine-tuning example (XLM-R)\n",
    "if 'train_loader' in globals():\n",
    "    num_labels = len(label_map)\n",
    "    model = TransformerClassifier(model_name='xlm-roberta-base', num_labels=num_labels)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    trainer = Trainer(model, optimizer, device=None, grad_clip=1.0, amp=False)\n",
    "\n",
    "    # Train 3-5 epochs with early stopping\n",
    "    history = trainer.fit(train_loader, val_loader, loss_fn=None, epochs=3, patience=2, save_path=str(ROOT / 'best_xlmroberta.pt'))\n",
    "    print('Training history:', history)\n",
    "else:\n",
    "    print('train_loader not available. Run the dataloader cell.')\n",
    "\n",
    "# BiLSTM baseline - placeholder\n",
    "# To run the BiLSTM baseline you need a tokenization -> integer vocab pipeline or provide pretrained embeddings.\n",
    "# A simple route: use tokenizer to obtain token ids from a BPE/wordpiece tokenizer and feed into the BiLSTM (as demonstration),\n",
    "# but note token ids reflect model vocab; you may instead build a new vocab using fastText or torchtext for a proper LSTM baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf30ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation: metrics, confusion matrix, ROC-AUC\n",
    "\n",
    "if 'trainer' in globals() and 'test_loader' in globals():\n",
    "    # load best model\n",
    "    best_path = str(ROOT / 'best_xlmroberta.pt')\n",
    "    if os.path.exists(best_path):\n",
    "        model.load_state_dict(torch.load(best_path))\n",
    "    preds, trues, _ = trainer.eval_epoch(test_loader)\n",
    "    metrics = compute_metrics(trues, preds, labels=list(label_map.keys()))\n",
    "    print('Evaluation metrics (summary):')\n",
    "    print('Accuracy:', metrics['accuracy'])\n",
    "    print('Macro F1:', metrics['macro_f1'])\n",
    "    display(metrics['report'])\n",
    "    plot_confusion(trues, preds, labels=list(label_map.keys()), save_path=str(ROOT / 'confusion.png'))\n",
    "else:\n",
    "    print('trainer or test_loader not defined; run previous cells to train and evaluate.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a9e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention visualization (sample)\n",
    "\n",
    "# This demonstrates how to request attention weights from the HF model and visualize them.\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if 'tokenizer' in globals() and 'model' in globals():\n",
    "    sample_text = (df['clean_text'].iloc[0] if 'df' in globals() else 'I love this product!')\n",
    "    enc = tokenizer(sample_text, return_tensors='pt')\n",
    "    # forward with attentions\n",
    "    model.model.config.output_attentions = True\n",
    "    out = model.model(**{k: v.to(model.model.device) for k,v in enc.items()})\n",
    "    # out.attentions is a tuple: (layer1, layer2, ...), each shape (batch, head, seq_len, seq_len)\n",
    "    attentions = out.attentions  # tuple\n",
    "    # pick the last layer and average heads\n",
    "    last = attentions[-1].squeeze(0).mean(axis=0).cpu().detach().numpy()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(enc['input_ids'].squeeze(0))\n",
    "    # plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.imshow(last[:len(tokens), :len(tokens)], cmap='viridis')\n",
    "    plt.xticks(range(len(tokens)), tokens, rotation=90)\n",
    "    plt.yticks(range(len(tokens)), tokens)\n",
    "    plt.colorbar()\n",
    "    plt.title('Average attention (last layer)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('tokenizer or model not available. Run tokenization and model cells first.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a802fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation study scaffold and cross-lingual test example\n",
    "\n",
    "from src.ablation import run_grid\n",
    "from src.cross_lingual import split_by_language, prepare_train_test_for_lang\n",
    "\n",
    "# Ablation: define a small grid (example). Replace `train_fn` with a function wrapping your training procedure.\n",
    "\n",
    "grid = {\n",
    "    'batch_size': [16, 32],\n",
    "    'lr': [2e-5, 5e-5],\n",
    "    'max_length': [128, 192]\n",
    "}\n",
    "\n",
    "print('Ablation scaffold created. To run sweeps, implement a train_fn(params) that trains and returns results dict, then call run_grid(train_fn, grid)')\n",
    "\n",
    "# Cross-lingual example\n",
    "if 'df' in globals():\n",
    "    groups = split_by_language(df, lang_col='language')\n",
    "    print('Languages found:', list(groups.keys()))\n",
    "    # example: train on sw (Swahili) and test on en and am\n",
    "    if 'sw' in groups:\n",
    "        train_df, val_df, test_df = prepare_train_test_for_lang(groups, train_langs=['sw'], test_langs=['en','am'])\n",
    "        print('Train size (sw):', len(train_df), 'Test combined (en+am):', len(test_df))\n",
    "    else:\n",
    "        print('Swahili subset not found in data; adapt language codes to your dataset')\n",
    "else:\n",
    "    print('Dataframe `df` not loaded; run the load cell first.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e3f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save artifacts and short summary\n",
    "\n",
    "print('To save artifacts:')\n",
    "print('- model: torch.save(model.state_dict(), \"path\")')\n",
    "print('- tokenizer: tokenizer.save_pretrained(\"path\")')\n",
    "print('- training logs: save history dict or use TensorBoard')\n",
    "\n",
    "print('\\nWhen finished, populate REPORT.md with key tables and plots from the notebook (confusion matrix, ablation results, cross-lingual transfer table).')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
